{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para previsão do score de um filme no ranking do IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados:\n",
    "https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo diretórios \n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "ANALISE_DIR = os.path.join(BASE_DIR, 'analise')\n",
    "\n",
    "#Checando ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda info --env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para comparar os shapes para verificar % da base que ainda resta\n",
    "def compara_shapes(shape_end,shape_init):\n",
    "    \"\"\"Função que retorna % de comparação entre shapes, onde paramentro 1 é divisor e parametro 2 é dividendo\"\"\"\n",
    "    compara_apos_nan = round((shape_end/shape_init)*100,2)\n",
    "    compara_apos_nan = compara_apos_nan.rename({0:'%Linhas restantes',1:'%Colunas restantes'})\n",
    "    return compara_apos_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'movie_metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvo meu shape inicial\n",
    "shape_inicial = pd.Series(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifica valores da coluna cor\n",
    "df['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo coluna de link, cor do filme, linguagem e país, pois as mesmas não possuem relevância para o modelo\n",
    "df.drop(columns=['movie_imdb_link','color','country','language'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vendo colunas que possuem NaN\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crio dicionário com minhas colunas e a soma das suas linhas nulas e uma lista vazia\n",
    "nan_colunas = dict(df.isna().sum())\n",
    "nan_lista_deletar = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pego todas as colunas que possuem menos de 154 linhas nulas e adiciono na lista criada\n",
    "for key, value in nan_colunas.items():\n",
    "    if value <= 153 and value != 0:\n",
    "        nan_lista_deletar.append(key)\n",
    "        \n",
    "nan_lista_deletar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropo meu os NaN utilizando lista das colunas acima\n",
    "df.dropna(subset=nan_lista_deletar, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvo meu shape após exclusão de NaN\n",
    "shape_nan = pd.Series(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamo função que compara Shapes\n",
    "compara_shapes(shape_nan,shape_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ao ver que a maioria dos Filmes é R (Livre)\n",
    "df['content_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iremos substituir os NaN por R\n",
    "df['content_rating'].fillna('R', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ao ver que a distribuição está mais para a direita\n",
    "df['aspect_ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iremos substituir os NaN pela mediana\n",
    "df['aspect_ratio'].fillna(df['aspect_ratio'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E assim da mesma forma para o Faturamento e para o Orçamento\n",
    "df['budget'].fillna(df['budget'].median(), inplace=True)\n",
    "df['gross'].fillna(df['gross'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soma dos valores duplicados\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropo valores duplicados e salvo shape\n",
    "df.drop_duplicates(inplace=True)\n",
    "shape_duplicated = pd.Series(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chamo função que compara Shapes\n",
    "compara_shapes(shape_duplicated,shape_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando Váriaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variavel Lucro criada pela subtração do orçamento pelo valor arrecadado bruto\n",
    "df['profit'] = df['budget'].sub(df['gross'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crio % do Lucro em relação ao valor bruto\n",
    "df['profit_percentage'] = (df['profit']/df['gross'])*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando DataSet em csv\n",
    "df.to_csv(os.path.join(ANALISE_DIR, 'dados_imdb_analiseexpl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alguns Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui podemos ver que o orçamento é relacionado a nota do filme\n",
    "ggplot(aes(x='imdb_score', y='profit'),data=df) +\\\n",
    "    geom_line() +\\\n",
    "    stat_smooth(colour='blue', span=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui podemos ver que o número de likes no facebook é relacionado a nota do filme\n",
    "(ggplot(df)+\\\n",
    "    aes(x='imdb_score', y='movie_facebook_likes') +\\\n",
    "    geom_line() +\\\n",
    "    labs(title='Nota no IMDB x Likes no facebook', x='Nota no IMDB', y='Likes no facebook')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlaciona qual a nota do imdb com o ator principal do filme (nos 20 melhores filmes)\n",
    "plt.figure(figsize=(10,8))\n",
    "df = df.sort_values(by='imdb_score', ascending=False)\n",
    "df2 = df.head(20)\n",
    "ax = sns.pointplot(df2['actor_1_name'], df2['imdb_score'], hue=df2['movie_title'])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=40, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando algumas colunas que não possuem importancia\n",
    "df.drop(columns=['director_name','actor_1_name','actor_2_name',\n",
    "                 'actor_3_name','plot_keywords', 'movie_title',\n",
    "                'genres', 'profit','profit_percentage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparação das variáveis entre si\n",
    "corr = df.corr()\n",
    "sns.set_context('notebook', font_scale=1.0, rc={'lines.linewidt':2.5})\n",
    "plt.figure(figsize=(13,7))\n",
    "#Cria mascara para ver somente as variáveis correlatas\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask,1)]=True\n",
    "a = sns.heatmap(corr, mask=mask, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "rotx = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variaveis de likes no facebook são muito correlatas, precisamos modificar\n",
    "df['other_actors_facebook_likes'] = df['actor_2_facebook_likes'] + df['actor_3_facebook_likes']\n",
    "df.drop(columns=['actor_2_facebook_likes','actor_3_facebook_likes', 'cast_total_facebook_likes'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variaveis de review são muito correlatas, precisamos modificar\n",
    "df['critic_review_ratio'] = df['num_critic_for_reviews']/df['num_user_for_reviews']\n",
    "df.drop(columns=['num_critic_for_reviews','num_user_for_reviews'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora temos todas as variaveis com menos de 65% de correlação, podemos continuar\n",
    "corr = df.corr()\n",
    "sns.set_context('notebook', font_scale=1.0, rc={'lines.linewidt':2.5})\n",
    "plt.figure(figsize=(13,7))\n",
    "#Cria mascara para ver somente as variáveis correlatas\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask,1)]=True\n",
    "a = sns.heatmap(corr, mask=mask, annot=True, fmt='.2f')\n",
    "rotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\n",
    "rotx = a.set_yticklabels(a.get_yticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranformando variavel numerica para categorizar a nota de 1 a 4\n",
    "df['imdb_binned_score'] = pd.cut(df['imdb_score'], bins=[0,4,6,8,10], right=True, labels=False)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranformando faixa etaria em várias colunas \"booleanas\" de acordo com valor\n",
    "df = pd.get_dummies(data=df, columns=['content_rating'], prefix=['content_rating'], drop_first=True)\n",
    "shape_modelo = pd.Series(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para comparar shape\n",
    "compara_shapes(shape_modelo,shape_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando DataSet em csv\n",
    "df.to_csv(os.path.join(ANALISE_DIR, 'dados_imdb_analisemodelo.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os dfs de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando colunas para o modelo\n",
    "colunas_df = list()\n",
    "for coluna in df.columns:\n",
    "    if coluna[0:4] != 'imdb':\n",
    "        colunas_df.append(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando df para modelagem sem as colunas imdb_score e imdb_binned_score\n",
    "X = pd.DataFrame(columns=colunas_df, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= pd.DataFrame(columns=['imdb_binned_score'], data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando os dados\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando modelo\n",
    "logit = LogisticRegression(verbose=1, max_iter=1000)\n",
    "logit.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred = logit.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando acuracia\n",
    "cnf_matrix = metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    '''\n",
    "    This function print and plots the confusion matrix.\n",
    "    Normalization can be applied by setting \"normalize=True\"\n",
    "    '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i,format(cm[i,j], fmt),\n",
    "                horizontalalignment = 'center',\n",
    "                color='white' if cm[i,j] > thresh else 'black')\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predict label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploto Matriz de confusão\n",
    "plot_confusion_matrix(cnf_matrix,classes=['1','2','3','4'], title='Confusion Matrix not normalized Score IMDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui podemos ver que o df está desbalanceado, por isso do resultado que não acerta em 1 e acerta mais em 3\n",
    "df['imdb_binned_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report de precisão das classes\n",
    "print(metrics.classification_report(y_test,y_pred,target_names=['1','2','3','4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando modelo\n",
    "modelo_treinado='modelo_imdb.sav'\n",
    "pickle.dump(logit,open(modelo_treinado,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando o modelo\n",
    "modelo_carregado = pickle.load(open(modelo_treinado,'rb'))\n",
    "modelo_carregado.predict([X_test[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
